{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b35b32f8",
   "metadata": {},
   "source": [
    "Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e805b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from typing import Tuple, Optional\n",
    "import webbrowser\n",
    "from pathlib import Path\n",
    "from typing import Union, List\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d0e4f",
   "metadata": {},
   "source": [
    "Initial Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1f537bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrast_stretch(img_rgb):\n",
    "        img_float = img_rgb.astype(np.float32)\n",
    "        min_val = float(np.min(img_float))\n",
    "        max_val = float(np.max(img_float))\n",
    "        if max_val <= min_val + 1e-6:\n",
    "            return img_rgb.copy()\n",
    "        stretched = (img_float - min_val) / (max_val - min_val) * 255.0\n",
    "        return np.clip(stretched, 0, 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1116f3ad",
   "metadata": {},
   "source": [
    "Denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d0d5f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise(img_rgb, h=2.5, hColor=5, templateWindowSize=7, searchWindowSize=21, **kwargs):\n",
    "        # Ensure valid odd window sizes as required by OpenCV\n",
    "        templateWindowSize = int(templateWindowSize)\n",
    "        searchWindowSize = int(searchWindowSize)\n",
    "        if templateWindowSize % 2 == 0:\n",
    "            templateWindowSize += 1\n",
    "        if searchWindowSize % 2 == 0:\n",
    "            searchWindowSize += 1\n",
    "\n",
    "        img_bgr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)\n",
    "        filtered_bgr = cv2.fastNlMeansDenoisingColored(\n",
    "            img_bgr, None,\n",
    "            h=float(h),\n",
    "            hColor=float(hColor),\n",
    "            templateWindowSize=templateWindowSize,\n",
    "            searchWindowSize=searchWindowSize\n",
    "        )\n",
    "        return cv2.cvtColor(filtered_bgr, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be177291",
   "metadata": {},
   "source": [
    "Brightness improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7beaf28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma_correction(img_rgb, gamma=2.2):\n",
    "        normalized = img_rgb.astype(np.float32) / 255.0\n",
    "        corrected = np.power(normalized, 1.0 / float(gamma))\n",
    "        return np.clip(corrected * 255.0, 0, 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c27f88b",
   "metadata": {},
   "source": [
    "Colour Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "052a8f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def white_balance(img_rgb):\n",
    "        result = img_rgb.astype(np.float32)\n",
    "        avg = np.mean(result, axis=(0, 1))  # RGB means\n",
    "        avg_gray = float(np.mean(avg))\n",
    "        # avoid division by zero\n",
    "        scale = np.where(avg <= 1e-6, 1.0, avg_gray / avg)\n",
    "        result *= scale\n",
    "        return np.clip(result, 0, 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98cd038",
   "metadata": {},
   "source": [
    "Tone Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37475998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clahe_yuv_and_tone_correction_lab(img_rgb, clipLimit1=1.0, tileGridSize1=(2, 2), clipLimit2=0.1, tileGridSize2=(1, 1)):\n",
    "    # Convert RGB to BGR for OpenCV\n",
    "    img_bgr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    # First: CLAHE on YUV luminance channel\n",
    "    yuv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2YUV)\n",
    "    clahe_yuv = cv2.createCLAHE(clipLimit=clipLimit1, tileGridSize=tileGridSize1)\n",
    "    yuv[:, :, 0] = clahe_yuv.apply(yuv[:, :, 0])\n",
    "    enhanced_bgr = cv2.cvtColor(yuv, cv2.COLOR_YUV2BGR)\n",
    "    \n",
    "    # Second: CLAHE on LAB lightness channel\n",
    "    lab = cv2.cvtColor(enhanced_bgr, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe_lab = cv2.createCLAHE(clipLimit=clipLimit2, tileGridSize=tileGridSize2)\n",
    "    cl = clahe_lab.apply(l)\n",
    "    limg = cv2.merge((cl, a, b))\n",
    "    final_bgr = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n",
    "    \n",
    "    # Convert back to RGB\n",
    "    return cv2.cvtColor(final_bgr, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c78e63",
   "metadata": {},
   "source": [
    "Colour Saturation improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e08b58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saturation_enhance(img_rgb, max_boost=1.6, min_boost=1.1, fixedEnhance=1.36):\n",
    "        hsv = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2HSV)\n",
    "        h, s, v = cv2.split(hsv)\n",
    "        normalized_s = s.astype(np.float32) / 255.0\n",
    "        adaptive_scale = float(max_boost) - (float(max_boost) - float(min_boost)) * normalized_s\n",
    "        s_enhanced = np.clip(s.astype(np.float32) * adaptive_scale * fixedEnhance, 0, 255).astype(np.uint8)\n",
    "        enhanced_hsv = cv2.merge([h, s_enhanced, v])\n",
    "        return cv2.cvtColor(enhanced_hsv, cv2.COLOR_HSV2RGB)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5a2c53",
   "metadata": {},
   "source": [
    "Pipeline Stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15e13843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pipeline(img):\n",
    "    # Stage 1: Contrast stretching\n",
    "    img = contrast_stretch(img)\n",
    "\n",
    "    # Stage 2: Denoising\n",
    "    img = denoise(img)\n",
    "\n",
    "    # Stage 3: Gamma Correction\n",
    "    img = gamma_correction(img)\n",
    "\n",
    "    # Stage 4: White Balancing\n",
    "    img = white_balance(img)\n",
    "\n",
    "    # Stage 5: CLAHE\n",
    "    img = clahe_yuv_and_tone_correction_lab(img)\n",
    "\n",
    "    # Stage 6: HSV saturation enhancement (Adaptive + FIxed)\n",
    "    img = saturation_enhance(img)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca2eb6d",
   "metadata": {},
   "source": [
    "Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b78a55d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (1500, 2000, 3)\n",
      "Processed and saved: 0BYZodoqfSIog8Wq_86Pcw_output.jpg\n",
      "<class 'numpy.ndarray'> (2448, 3264, 3)\n",
      "Processed and saved: 0Gorezr4O2NfRAHkEfyZZg_output.jpg\n",
      "<class 'numpy.ndarray'> (1611, 1611, 3)\n",
      "Processed and saved: 0hfmiSEJtXFYhxs4XxR7PA_output.jpg\n",
      "<class 'numpy.ndarray'> (2448, 3264, 3)\n",
      "Processed and saved: 0tysbnnKZGOk-SyzweASaA_output.jpg\n",
      "<class 'numpy.ndarray'> (1200, 1600, 3)\n",
      "Processed and saved: 1a2bb6e318591cc40d280880bf23e259_output.jpg\n",
      "<class 'numpy.ndarray'> (2448, 3264, 3)\n",
      "Processed and saved: 1BvLhmNMa6A3aTiKezxSXA_output.jpg\n",
      "<class 'numpy.ndarray'> (1823, 4032, 3)\n",
      "Processed and saved: 1QE42YpA12FL6uWezE-d1w_output.jpg\n",
      "<class 'numpy.ndarray'> (1561, 3264, 3)\n",
      "Processed and saved: 1_wVzEv_cTx9P00b62WOGg_output.jpg\n",
      "<class 'numpy.ndarray'> (2448, 3264, 3)\n",
      "Processed and saved: 2-CkLq8O-FDPSzxodmBCiQ_output.jpg\n",
      "<class 'numpy.ndarray'> (1060, 1600, 3)\n",
      "Processed and saved: 2b3f30bd3ea9a4fe2fd1bb556551b621_output.jpg\n",
      "<class 'numpy.ndarray'> (1453, 3264, 3)\n",
      "Processed and saved: 2J_PWeEiGEgP3R8RM85j2w_output.jpg\n",
      "<class 'numpy.ndarray'> (2448, 3264, 3)\n",
      "Processed and saved: 4JeeUs0EFETa_bGCGi3PMA_output.jpg\n",
      "<class 'numpy.ndarray'> (1781, 2565, 3)\n",
      "Processed and saved: 4LjjJT9HVf2y9RVs62Vjhw_output.jpg\n",
      "<class 'numpy.ndarray'> (6240, 4160, 3)\n",
      "Processed and saved: 534214591O-1755123030695_output.jpg\n",
      "<class 'numpy.ndarray'> (5860, 3907, 3)\n",
      "Processed and saved: 534214601O-1755123413282_output.jpg\n",
      "<class 'numpy.ndarray'> (3024, 4032, 3)\n",
      "Processed and saved: 610613773O-1755128982454_output.jpg\n",
      "<class 'numpy.ndarray'> (3024, 4032, 3)\n",
      "Processed and saved: 611789017O-1755181075831_output.jpg\n",
      "<class 'numpy.ndarray'> (4096, 3067, 3)\n",
      "Processed and saved: 615884301O-1755179612263_output.jpg\n",
      "<class 'numpy.ndarray'> (3906, 2927, 3)\n",
      "Processed and saved: 615884905O-1755180014908_output.jpg\n",
      "<class 'numpy.ndarray'> (3000, 4000, 3)\n",
      "Processed and saved: 616268973O-1755045862046_output.jpg\n",
      "<class 'numpy.ndarray'> (1600, 1200, 3)\n",
      "Processed and saved: 617615935O-1752160354109_output.jpg\n",
      "<class 'numpy.ndarray'> (1063, 1415, 3)\n",
      "Processed and saved: 619108157O-1753118091896_output.jpg\n",
      "<class 'numpy.ndarray'> (1106, 1472, 3)\n",
      "Processed and saved: 619108161O-1753118092020_output.jpg\n",
      "<class 'numpy.ndarray'> (1024, 1024, 3)\n",
      "Processed and saved: 689a05ba-a3eb-41f9-baaf-6e55f388e667_output.jpg\n",
      "<class 'numpy.ndarray'> (1365, 1024, 3)\n",
      "Processed and saved: 6h78awh_1730112077_527702079_optOrig_output.jpg\n",
      "<class 'numpy.ndarray'> (920, 736, 3)\n",
      "Processed and saved: 7af42e48362503024bcaab2b147adf51_output.jpg\n",
      "<class 'numpy.ndarray'> (1080, 1438, 3)\n",
      "Processed and saved: 8a9fcf8283074fdf018307a2265541c7_168601_278656_large_output.jpg\n",
      "<class 'numpy.ndarray'> (1365, 1024, 3)\n",
      "Processed and saved: 8updtmy_1730112639_527704645_optOrig_output.jpg\n",
      "<class 'numpy.ndarray'> (1200, 1600, 3)\n",
      "Processed and saved: alberts-flat-2_output.jpg\n",
      "<class 'numpy.ndarray'> (1200, 1600, 3)\n",
      "Processed and saved: b44f36e55b6c3230e76ef355b1c43bca_output.jpg\n",
      "<class 'numpy.ndarray'> (1342, 1920, 3)\n",
      "Processed and saved: corrugated-roof-village-home-design_output.jpg\n",
      "<class 'numpy.ndarray'> (1365, 1024, 3)\n",
      "Processed and saved: d08d6do_1730112076_527702071_optOrig_output.jpg\n",
      "<class 'numpy.ndarray'> (1438, 2560, 3)\n",
      "Processed and saved: DJI_0309-2-1714825544-scaled_output.jpg\n",
      "<class 'numpy.ndarray'> (1200, 1600, 3)\n",
      "Processed and saved: DSC06268_output.jpg\n",
      "<class 'numpy.ndarray'> (1024, 1024, 3)\n",
      "Processed and saved: e5f35921-8877-473a-ba3c-2fc935fe8574_output.jpg\n",
      "<class 'numpy.ndarray'> (1200, 1200, 3)\n",
      "Processed and saved: eedf5b17-fed2-8138-c48d-49a4ee800008_output.jpg\n",
      "<class 'numpy.ndarray'> (1568, 2560, 3)\n",
      "Processed and saved: exterior-prabu-shankar-photography-img~9091b32708c3e2c0_14-4962-1-014eac2_output.jpg\n",
      "<class 'numpy.ndarray'> (1067, 1600, 3)\n",
      "Processed and saved: f7a7444becdd0f1e2a9e8e49551c9246_output.jpg\n",
      "<class 'numpy.ndarray'> (900, 1600, 3)\n",
      "Processed and saved: image (1)_output.png\n",
      "<class 'numpy.ndarray'> (1300, 1600, 3)\n",
      "Processed and saved: image (n)_output.png\n",
      "<class 'numpy.ndarray'> (190, 265, 3)\n",
      "Processed and saved: imagea_output.png\n",
      "<class 'numpy.ndarray'> (899, 1600, 3)\n",
      "Processed and saved: imageb_output.png\n",
      "<class 'numpy.ndarray'> (800, 1600, 3)\n",
      "Processed and saved: imagec_output.png\n",
      "<class 'numpy.ndarray'> (1069, 1600, 3)\n",
      "Processed and saved: imaged_output.png\n",
      "<class 'numpy.ndarray'> (1067, 1600, 3)\n",
      "Processed and saved: imagef_output.png\n",
      "<class 'numpy.ndarray'> (1067, 1600, 3)\n",
      "Processed and saved: imageg_output.png\n",
      "<class 'numpy.ndarray'> (1067, 1600, 3)\n",
      "Processed and saved: imageh_output.png\n",
      "<class 'numpy.ndarray'> (960, 1600, 3)\n",
      "Processed and saved: imagei_output.png\n",
      "<class 'numpy.ndarray'> (1066, 1600, 3)\n",
      "Processed and saved: imagej_output.png\n",
      "<class 'numpy.ndarray'> (900, 1600, 3)\n",
      "Processed and saved: imagek_output.png\n",
      "<class 'numpy.ndarray'> (1200, 1600, 3)\n",
      "Processed and saved: imagem_output.png\n",
      "<class 'numpy.ndarray'> (1025, 1600, 3)\n",
      "Processed and saved: imageo_output.png\n",
      "<class 'numpy.ndarray'> (1061, 1600, 3)\n",
      "Processed and saved: imagep_output.png\n",
      "<class 'numpy.ndarray'> (1200, 1600, 3)\n",
      "Processed and saved: imagepp_output.png\n",
      "<class 'numpy.ndarray'> (960, 1600, 3)\n",
      "Processed and saved: imager_output.png\n",
      "<class 'numpy.ndarray'> (1067, 1600, 3)\n",
      "Processed and saved: images_output.png\n",
      "<class 'numpy.ndarray'> (1068, 1600, 3)\n",
      "Processed and saved: imagew_output.png\n",
      "<class 'numpy.ndarray'> (1068, 1600, 3)\n",
      "Processed and saved: imagex_output.png\n",
      "<class 'numpy.ndarray'> (1044, 1600, 3)\n",
      "Processed and saved: imagey_output.png\n",
      "<class 'numpy.ndarray'> (1080, 1440, 3)\n",
      "Processed and saved: imagez_output.png\n",
      "<class 'numpy.ndarray'> (1707, 2560, 3)\n",
      "Processed and saved: IMG_4712-scaled_output.jpg\n",
      "<class 'numpy.ndarray'> (900, 1600, 3)\n",
      "Processed and saved: imj_output.png\n",
      "<class 'numpy.ndarray'> (1456, 2592, 3)\n",
      "Processed and saved: Indian_village_home_output.jpg\n",
      "<class 'numpy.ndarray'> (1024, 1024, 3)\n",
      "Processed and saved: ongriddesign_blog_triplex_elevation_1024x1024_output.jpg\n",
      "<class 'numpy.ndarray'> (3393, 5264, 3)\n",
      "Processed and saved: pexels-expect-best-79873-323780_output.jpg\n",
      "<class 'numpy.ndarray'> (1687, 3000, 3)\n",
      "Processed and saved: photo-1516180598628-a57a3dda1a80_output.jpg\n",
      "<class 'numpy.ndarray'> (2000, 3000, 3)\n",
      "Processed and saved: photo-1558036117-15d82a90b9b1_output.jpg\n",
      "<class 'numpy.ndarray'> (2362, 3000, 3)\n",
      "Processed and saved: photo-1568293207619-df44ae062a9c_output.jpg\n",
      "<class 'numpy.ndarray'> (2250, 3000, 3)\n",
      "Processed and saved: photo-1590520326731-ddeee2bfebf8_output.jpg\n",
      "<class 'numpy.ndarray'> (2250, 3000, 3)\n",
      "Processed and saved: photo-1591474200742-8e512e6f98f8_output.jpg\n",
      "<class 'numpy.ndarray'> (2000, 3000, 3)\n",
      "Processed and saved: photo-1604062215216-f417b2778726_output.jpg\n",
      "<class 'numpy.ndarray'> (2250, 3000, 3)\n",
      "Processed and saved: photo-1663057276815-0e07863a2e46_output.jpg\n",
      "<class 'numpy.ndarray'> (2250, 3000, 3)\n",
      "Processed and saved: premium_photo-1661883982941-50af7720a6ff_output.jpg\n",
      "<class 'numpy.ndarray'> (2000, 3000, 3)\n",
      "Processed and saved: premium_photo-1680300960892-bd11b59b469b (1)_output.jpg\n",
      "<class 'numpy.ndarray'> (2000, 3000, 3)\n",
      "Processed and saved: premium_photo-1680300960892-bd11b59b469b_output.jpg\n",
      "<class 'numpy.ndarray'> (4500, 3000, 3)\n",
      "Processed and saved: premium_photo-1692388619456-641ea333bcb6_output.jpg\n",
      "<class 'numpy.ndarray'> (2136, 3216, 3)\n",
      "Processed and saved: R_output.jpg\n",
      "<class 'numpy.ndarray'> (1503, 2000, 3)\n",
      "Processed and saved: RAW_Architecture_-_Kembang_Murni_House_16_output.jpg\n",
      "<class 'numpy.ndarray'> (1280, 1920, 3)\n",
      "Processed and saved: Repropix-Exterior-Images-P2-4_output.jpg\n",
      "<class 'numpy.ndarray'> (1365, 2048, 3)\n",
      "Processed and saved: Residential-13-2048x1365_output.jpg\n",
      "<class 'numpy.ndarray'> (1280, 1147, 3)\n",
      "Processed and saved: ujknskv_output.jpg\n",
      "<class 'numpy.ndarray'> (1200, 1600, 3)\n",
      "Processed and saved: usncks_output.jpg\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "Processed and saved: vmkrkdp_1744113911_584796911_optOrig_output.jpg\n",
      "<class 'numpy.ndarray'> (1072, 1500, 3)\n",
      "Processed and saved: WhatsApp Image 2025-08-25 at 12.42.47_output.jpeg\n",
      "<class 'numpy.ndarray'> (1121, 1600, 3)\n",
      "Processed and saved: WhatsApp Image 2025-08-25 at 12.46.30_output.jpeg\n",
      "<class 'numpy.ndarray'> (1066, 1600, 3)\n",
      "Processed and saved: WhatsApp Image 2025-08-25 at 12.48.16_output.jpeg\n",
      "<class 'numpy.ndarray'> (900, 1600, 3)\n",
      "Processed and saved: WhatsApp Image 2025-08-25 at 12.50.27_output.jpeg\n",
      "<class 'numpy.ndarray'> (960, 1600, 3)\n",
      "Processed and saved: WhatsApp Image 2025-08-25 at 14.00.05_output.jpeg\n",
      "<class 'numpy.ndarray'> (1066, 1600, 3)\n",
      "Processed and saved: WhatsApp-Image-2023-02-03-at-5.33.48-PM-1_output.jpg\n",
      "<class 'numpy.ndarray'> (1472, 2560, 3)\n",
      "Processed and saved: wide-front-scaled_output.jpg\n",
      "<class 'numpy.ndarray'> (1024, 1024, 3)\n",
      "Processed and saved: Winterlake-Ooty-Villa-Venkitesh-6-1024x1024_output.jpg\n",
      "<class 'numpy.ndarray'> (1365, 1024, 3)\n",
      "Processed and saved: zhcvmme_1730112639_527704643_optOrig_output.jpg\n",
      "<class 'numpy.ndarray'> (2448, 3264, 3)\n",
      "Processed and saved: _0ZLZEpBrN8d2YGqPYQSlA_output.jpg\n",
      "<class 'numpy.ndarray'> (2160, 4096, 3)\n",
      "Processed and saved: _69EblZbqXUcjYKu7myKDg_output.jpg\n",
      "<class 'numpy.ndarray'> (2448, 3264, 3)\n",
      "Processed and saved: _oU4UcfQXBoljdL-s1EDyQ_output.jpg\n"
     ]
    }
   ],
   "source": [
    "input_folder = \"C:/Users/gaura/Current_Code_Files/Internship_Project/house_exterior_data - 2/Batch1/Primary_Exterior_Dataset\"\n",
    "output_folder = \"C:/Users/gaura/Current_Code_Files/Internship_Project/OutputImages\"\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.lower().endswith((\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tiff\")):\n",
    "        img_path = os.path.join(input_folder, filename)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "        if img is None:\n",
    "            print(f\"Skipping {filename} (cannot read image)\")\n",
    "            continue\n",
    "\n",
    "        processed = process_pipeline(img)\n",
    "\n",
    "        # Split name and extension\n",
    "        name, ext = os.path.splitext(filename)\n",
    "        out_filename = f\"{name}_output{ext}\"\n",
    "\n",
    "        out_path = os.path.join(output_folder, out_filename)\n",
    "        print(type(processed), processed.shape if processed is not None else None)\n",
    "        cv2.imwrite(out_path, processed)\n",
    "        print(f\"Processed and saved: {out_filename}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cfd703a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML file generated and opened: comparison_01.html\n"
     ]
    }
   ],
   "source": [
    "input_folder = \"C:/Users/gaura/Current_Code_Files/Internship_Project/house_exterior_data - 2/Batch1/Primary_Exterior_Dataset\"\n",
    "output_folder = \"C:/Users/gaura/Current_Code_Files/Internship_Project/OutputImages\"\n",
    "html_file = \"comparison_01.html\"\n",
    "\n",
    "# Allowed image extensions\n",
    "IMAGE_EXTS = {\".png\", \".jpg\", \".jpeg\"}\n",
    "\n",
    "def is_image(fname):\n",
    "    return os.path.splitext(fname)[1].lower() in IMAGE_EXTS\n",
    "\n",
    "input_images = [f for f in os.listdir(input_folder) if is_image(f)]\n",
    "output_images = [f for f in os.listdir(output_folder) if is_image(f)]\n",
    "\n",
    "output_map = {}\n",
    "for out_img in output_images:\n",
    "    name, ext = os.path.splitext(out_img)\n",
    "    if name.lower().endswith(\"_output\"):\n",
    "        base = name[:-7]\n",
    "    else:\n",
    "        base = name\n",
    "    output_map[base.lower()] = out_img  \n",
    "\n",
    "# HTML content\n",
    "html_content = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <title>Image Comparison</title>\n",
    "    <style>\n",
    "        body {\n",
    "            font-family: Arial, sans-serif;\n",
    "            background: #f4f4f4;\n",
    "            padding: 20px;\n",
    "        }\n",
    "        .pair {\n",
    "            display: flex;\n",
    "            justify-content: center;\n",
    "            align-items: flex-start;\n",
    "            margin-bottom: 30px;\n",
    "            background: #fff;\n",
    "            padding: 15px;\n",
    "            border-radius: 8px;\n",
    "            box-shadow: 0px 2px 6px rgba(0,0,0,0.2);\n",
    "        }\n",
    "        .image-container {\n",
    "            text-align: center;\n",
    "            margin: 0 15px;\n",
    "        }\n",
    "        img {\n",
    "            max-width: 400px;\n",
    "            height: auto;\n",
    "            border-radius: 6px;\n",
    "            border: 1px solid #ccc;\n",
    "        }\n",
    "        .caption {\n",
    "            margin-top: 8px;\n",
    "            font-weight: bold;\n",
    "        }\n",
    "        .missing {\n",
    "            color: red;\n",
    "            font-weight: bold;\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>Input vs Output Image Comparison</h1>\n",
    "\"\"\"\n",
    "\n",
    "for in_img in sorted(input_images, key=str.lower):\n",
    "    base, _ = os.path.splitext(in_img)\n",
    "    out_img = output_map.get(base.lower()) \n",
    "    html_content += f\"\"\"\n",
    "    <div class=\"pair\">\n",
    "        <div class=\"image-container\">\n",
    "            <img src=\"{input_folder}/{in_img}\" alt=\"Input Image\">\n",
    "            <div class=\"caption\">Input: {in_img}</div>\n",
    "        </div>\n",
    "    \"\"\"\n",
    "    if out_img:\n",
    "        html_content += f\"\"\"\n",
    "        <div class=\"image-container\">\n",
    "            <img src=\"{output_folder}/{out_img}\" alt=\"Output Image\">\n",
    "            <div class=\"caption\">Output: {out_img}</div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    else:\n",
    "        html_content += f\"\"\"\n",
    "        <div class=\"image-container\">\n",
    "            <div class=\"missing\"> No matching output found</div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    html_content += \"</div>\"\n",
    "\n",
    "html_content += \"\"\"\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# Save HTML file\n",
    "with open(html_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(html_content)\n",
    "\n",
    "webbrowser.open(\"file://\" + os.path.abspath(html_file))\n",
    "\n",
    "print(f\"HTML file generated and opened: {html_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8045ac1",
   "metadata": {},
   "source": [
    "Dataset division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "947b299a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files found: 19658\n",
      "Created C:/Users/gaura/Current_Code_Files/Internship_Project/BatchedDataset\\batch_1 with 200 files\n",
      "Created C:/Users/gaura/Current_Code_Files/Internship_Project/BatchedDataset\\batch_2 with 200 files\n",
      "Created C:/Users/gaura/Current_Code_Files/Internship_Project/BatchedDataset\\batch_3 with 200 files\n",
      "Created C:/Users/gaura/Current_Code_Files/Internship_Project/BatchedDataset\\batch_4 with 200 files\n",
      "Created C:/Users/gaura/Current_Code_Files/Internship_Project/BatchedDataset\\batch_5 with 200 files\n",
      "Created C:/Users/gaura/Current_Code_Files/Internship_Project/BatchedDataset\\batch_6 with 200 files\n",
      "Created C:/Users/gaura/Current_Code_Files/Internship_Project/BatchedDataset\\batch_7 with 200 files\n",
      "Created C:/Users/gaura/Current_Code_Files/Internship_Project/BatchedDataset\\batch_8 with 200 files\n",
      "Created C:/Users/gaura/Current_Code_Files/Internship_Project/BatchedDataset\\batch_9 with 200 files\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[32m     39\u001b[39m input_folder = \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:/Users/gaura/Current_Code_Files/Internship_Project/house_exterior_data\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     40\u001b[39m output_folder = \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:/Users/gaura/Current_Code_Files/Internship_Project/BatchedDataset\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m \u001b[43msplit_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36msplit_dataset\u001b[39m\u001b[34m(input_folder, output_folder, batch_size)\u001b[39m\n\u001b[32m     31\u001b[39m     src = os.path.join(input_folder, file)\n\u001b[32m     32\u001b[39m     dst = os.path.join(batch_folder, file)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     \u001b[43mshutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCreated \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(batch_files)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m files\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     36\u001b[39m batch_num += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python313\\Lib\\shutil.py:428\u001b[39m, in \u001b[36mcopy\u001b[39m\u001b[34m(src, dst, follow_symlinks)\u001b[39m\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m os.path.isdir(dst):\n\u001b[32m    427\u001b[39m     dst = os.path.join(dst, os.path.basename(src))\n\u001b[32m--> \u001b[39m\u001b[32m428\u001b[39m \u001b[43mcopyfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    429\u001b[39m copymode(src, dst, follow_symlinks=follow_symlinks)\n\u001b[32m    430\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m dst\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python313\\Lib\\shutil.py:260\u001b[39m, in \u001b[36mcopyfile\u001b[39m\u001b[34m(src, dst, follow_symlinks)\u001b[39m\n\u001b[32m    258\u001b[39m     os.symlink(os.readlink(src), dst)\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m260\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fsrc:\n\u001b[32m    261\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    262\u001b[39m             \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(dst, \u001b[33m'\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fdst:\n\u001b[32m    263\u001b[39m                 \u001b[38;5;66;03m# macOS\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def split_dataset(input_folder, output_folder, batch_size=200):\n",
    "    \"\"\"\n",
    "    Splits images from input_folder into batches of given size\n",
    "    and saves them in subfolders inside output_folder.\n",
    "    \n",
    "    Example:\n",
    "        batch_1 -> first 200 images\n",
    "        batch_2 -> next 200 images\n",
    "        ...\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # List all files in input folder\n",
    "    files = [f for f in os.listdir(input_folder) \n",
    "             if os.path.isfile(os.path.join(input_folder, f))]\n",
    "\n",
    "    total_files = len(files)\n",
    "    print(f\"Total files found: {total_files}\")\n",
    "\n",
    "    batch_num = 1\n",
    "    for i in range(0, total_files, batch_size):\n",
    "        batch_files = files[i:i+batch_size]\n",
    "        batch_folder = os.path.join(output_folder, f\"batch_{batch_num}\")\n",
    "        os.makedirs(batch_folder, exist_ok=True)\n",
    "\n",
    "        for file in batch_files:\n",
    "            src = os.path.join(input_folder, file)\n",
    "            dst = os.path.join(batch_folder, file)\n",
    "            shutil.copy(src, dst)\n",
    "\n",
    "        print(f\"Created {batch_folder} with {len(batch_files)} files\")\n",
    "        batch_num += 1\n",
    "\n",
    "# Example usage\n",
    "input_folder = r\"C:/Users/gaura/Current_Code_Files/Internship_Project/house_exterior_data\"\n",
    "output_folder = r\"C:/Users/gaura/Current_Code_Files/Internship_Project/BatchedDataset\"\n",
    "split_dataset(input_folder, output_folder, batch_size=200)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ComputerVision_internship",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
